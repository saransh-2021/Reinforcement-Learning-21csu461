{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments\n",
    "REWARD = -0.01 # constant reward for non-terminal states\n",
    "DISCOUNT = 0.9 # discount factor\n",
    "MAX_ERROR = 10**(-3) # max error for convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the initial environment\n",
    "NUM_ACTIONS = 4\n",
    "ACTIONS = [(1, 0), (0, -1), (-1, 0), (0, 1)] # Down, Left, Up, Right\n",
    "NUM_ROW = 3 # number of rows\n",
    "NUM_COL = 4 # number of columns\n",
    "U = [[0, 0, 0, 1], [0, 0, 0, -1], [0, 0, 0, 0], [0, 0, 0, 0]] # initial utility\n",
    "policy = [[random.randint(0, 3) for j in range(NUM_COL)] for i in range(NUM_ROW)] # construct a random policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "def printEnvironment(arr, policy=False):\n",
    "    \"\"\" Print the environment in a readable format \"\"\"\n",
    "    res = \"\"\n",
    "    for r in range(NUM_ROW):\n",
    "        res += \"|\"\n",
    "        for c in range(NUM_COL):\n",
    "            if r == c == 1:\n",
    "                val = \"WALL\"\n",
    "            elif r <= 1 and c == 3:\n",
    "                val = \"+1\" if r == 0 else \"-1\"\n",
    "            else:\n",
    "                val = [\"Down\", \"Left\", \"Up\", \"Right\"][arr[r][c]]\n",
    "            res += \" \" + val[:5].ljust(5) + \" |\" # format\n",
    "        res += \"\\n\"\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the utility of the state reached by performing the given action from the given state\n",
    "def getU(U, r, c, action):\n",
    "    \"\"\"Return the utility of the state reached by performing the given action from the given state.\"\"\"\n",
    "    dr, dc = ACTIONS[action] # get the change in row and column\n",
    "    newR, newC = r+dr, c+dc # get the new row and column\n",
    "    if newR < 0 or newC < 0 or newR >= NUM_ROW or newC >= NUM_COL or (newR == newC == 1): # collide with the boundary or the wall\n",
    "        return U[r][c]\n",
    "    else:\n",
    "        return U[newR][newC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the utility of a state given an action\n",
    "def calculateU(U, r, c, action):\n",
    "    \"\"\" Calculate the utility of a state given an action.\"\"\"\n",
    "    u = REWARD\n",
    "    u += 0.1 * DISCOUNT * getU(U, r, c, (action-1)%4)\n",
    "    u += 0.8 * DISCOUNT * getU(U, r, c, action)\n",
    "    u += 0.1 * DISCOUNT * getU(U, r, c, (action+1)%4)\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform some simplified value iteration steps to get an approximation of the utilities\n",
    "def policyEvaluation(policy, U):\n",
    "    \"\"\" Perform some simplified value iteration steps to get an approximation of the utilities. \"\"\"\n",
    "    while True:\n",
    "        nextU = [[0, 0, 0, 1], [0, 0, 0, -1], [0, 0, 0, 0], [0, 0, 0, 0]]\n",
    "        error = 0\n",
    "        for r in range(NUM_ROW):\n",
    "            for c in range(NUM_COL):\n",
    "                if (r <= 1 and c == 3) or (r == c == 1):\n",
    "                    continue\n",
    "                nextU[r][c] = calculateU(U, r, c, policy[r][c]) # simplified Bellman update\n",
    "                error = max(error, abs(nextU[r][c]-U[r][c]))\n",
    "        U = nextU\n",
    "        if error < MAX_ERROR * (1-DISCOUNT) / DISCOUNT:\n",
    "            break\n",
    "    return U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policyIteration(policy, U):\n",
    "    \"\"\" Perform policy iteration. \"\"\"\n",
    "    print(\"During the policy iteration:\\n\")\n",
    "    while True:\n",
    "        U = policyEvaluation(policy, U)\n",
    "        unchanged = True\n",
    "        for r in range(NUM_ROW):\n",
    "            for c in range(NUM_COL):\n",
    "                if (r <= 1 and c == 3) or (r == c == 1):\n",
    "                    continue\n",
    "                maxAction, maxU = None, -float(\"inf\")\n",
    "                for action in range(NUM_ACTIONS):\n",
    "                    u = calculateU(U, r, c, action)\n",
    "                    if u > maxU:\n",
    "                        maxAction, maxU = action, u\n",
    "                if maxU > calculateU(U, r, c, policy[r][c]):\n",
    "                    policy[r][c] = maxAction # the action that maximizes the utility\n",
    "                    unchanged = False\n",
    "        if unchanged:\n",
    "            break\n",
    "        printEnvironment(policy)\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial random policy is:\n",
      "\n",
      "| Down  | Down  | Up    | +1    |\n",
      "| Left  | WALL  | Right | -1    |\n",
      "| Left  | Up    | Left  | Right |\n",
      "\n",
      "During the policy iteration:\n",
      "\n",
      "| Right | Right | Right | +1    |\n",
      "| Up    | WALL  | Up    | -1    |\n",
      "| Left  | Left  | Left  | Left  |\n",
      "\n",
      "| Right | Right | Right | +1    |\n",
      "| Up    | WALL  | Up    | -1    |\n",
      "| Up    | Left  | Up    | Down  |\n",
      "\n",
      "| Right | Right | Right | +1    |\n",
      "| Up    | WALL  | Up    | -1    |\n",
      "| Up    | Left  | Up    | Left  |\n",
      "\n",
      "| Right | Right | Right | +1    |\n",
      "| Up    | WALL  | Up    | -1    |\n",
      "| Up    | Right | Up    | Left  |\n",
      "\n",
      "The optimal policy is:\n",
      "\n",
      "| Right | Right | Right | +1    |\n",
      "| Up    | WALL  | Up    | -1    |\n",
      "| Up    | Right | Up    | Left  |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the initial environment\n",
    "print(\"The initial random policy is:\\n\")\n",
    "printEnvironment(policy)\n",
    "\n",
    "# Policy iteration\n",
    "policy = policyIteration(policy, U)\n",
    "\n",
    "# Print the optimal policy\n",
    "print(\"The optimal policy is:\\n\")\n",
    "printEnvironment(policy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
